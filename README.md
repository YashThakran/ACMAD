<h1 align="center">
<p>ACMAD :curly_loop:</p>
<p align="center">
<img alt="GitHub" src="https://img.shields.io/github/license/cross-caps/AFLI?color=green&logo=GNU&logoColor=green">
<img alt="python" src="https://img.shields.io/badge/python-%3E%3D3.8-blue?logo=python">
<img alt="pytorch" src="https://img.shields.io/badge/pytorch-%3E%3D1.8-orange?logo=pytorch">
<img alt="PyPI" src="https://img.shields.io/badge/release-v1.0-brightgreen?logo=apache&logoColor=brightgreen">
</p>
</h1>

<h2 align="center">
<p>Acoustic Cues for Multilingual Abuse Detection</p>
</h2>

Code to acompanying Interspeech-23 Paper:
Investigating Acoustic Cues for Multilingual Abuse Detection

## Feature Extraction

- Download the extracted language and emotion features of [ADIMA](https://sharechat.com/research/adima) dataset from [here](https://tinyurl.com/extractedfeatures). 

## Training and Testing

- For training the model from scratch; see [Script](./train.py).
- For testing the model using our best saved checkpoint; see [Script](./test.py).

## Contact

Yash Thakran <yash20269@iiitd.ac.in>

Dr. Vinayak Abrol <abrol@iiitd.ac.in>
